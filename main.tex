\documentclass[11pt,a4paper]{article}

% Essential packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[margin=2cm]{geometry}
\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{enumitem}
\usepackage{multicol}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{amsmath}
\usepackage{url}

% Compact formatting
\setlength{\parskip}{0.2em}
\setlength{\belowcaptionskip}{-5pt}
\setlist{nosep, leftmargin=*, topsep=1pt, itemsep=0.5pt}
\titlespacing*{\section}{0pt}{6pt}{3pt}
\titlespacing*{\subsection}{0pt}{4pt}{2pt}
\titlespacing*{\subsubsection}{0pt}{3pt}{1pt}
\setlength{\floatsep}{8pt}
\setlength{\textfloatsep}{10pt}

% Hyperref configuration
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor=cyan,
    citecolor=blue,
    pdftitle={Multi-Tier Cloud Architecture Design for SONYC RAG Application}
}

% Headers and footers
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\small Multi-Tier Cloud Architecture Design for SONYC}
\fancyhead[R]{\small \thepage}
\fancyfoot[C]{\small BESE29-A - Cloud Computing (SE-315)}

% Title formatting
\titleformat{\section}{\Large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\large\bfseries}{\thesubsection}{1em}{}
\titleformat{\subsubsection}{\normalsize\bfseries}{\thesubsubsection}{1em}{}

\begin{document}

% Executive Summary
\section*{Executive Summary}

This document presents a comprehensive cloud architecture design for SONYC (Streaming ChatBot), a Retrieval-Augmented Generation (RAG) application deployed on Amazon Web Services (AWS). The architecture addresses security, scalability, reliability, and operational excellence for a production-grade multi-tier web application with fault tolerance, high availability, and cost optimization.

\subsection*{Deployment Status and Architecture Scope}

The current deployment is a simplified development environment. This document focuses on production architecture meeting 99.9\% availability through Multi-AZ deployment, high availability, production-grade security, comprehensive monitoring, and auto-scaling for 100--1000+ concurrent users.

\begin{longtable}{|p{3cm}|p{5.5cm}|p{5.5cm}|}
\hline
\textbf{Component} & \textbf{Development} & \textbf{Production Design} \\
\hline
\textbf{EC2} & Single (m7i-flex.large) & Multiple (t3.large) with ASG \\
\hline
\textbf{AZ} & Single (eu-north-1b) & Multi-AZ (eu-north-1a, 1b) \\
\hline
\textbf{RDS} & db.t4g.micro, Single-AZ & db.t3.medium, Multi-AZ \\
\hline
\textbf{Security} & Broad access (dev config) & Least privilege, restricted \\
\hline
\textbf{Network} & Simple VPC & Multi-tier (ALB, CloudFront) \\
\hline
\end{longtable}

% Section 1: Architecture Diagrams
\section{High-Level Architecture Diagram}

The SONYC application follows a three-tier architecture with clear separation: presentation (CloudFront, Next.js), application (ALB, FastAPI on EC2), and data (RDS PostgreSQL, S3 vector stores).

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.85\textwidth]{Figure 1.png}
    \caption{High-Level Architecture Diagram - Multi-Tier Cloud Deployment}
\end{figure}

\textbf{Key Components:}
\begin{itemize}
    \item \textbf{Tier 1}: CloudFront CDN, Next.js frontend, S3 static assets
    \item \textbf{Tier 2}: ALB, FastAPI backend (Auto Scaling Group)
    \item \textbf{Tier 3}: RDS PostgreSQL (Multi-AZ), S3 vector stores
    \item \textbf{External}: Google AI, HuggingFace API, GitHub API, Tavily API
\end{itemize}

\textbf{Trust Boundaries:} (1) Internet--CloudFront (WAF/Shield), (2) CloudFront--ALB (security groups), (3) Backend--Database (network ACLs), (4) Data access (IAM, encryption)

\subsection{Data Flow}

\textbf{Request Flow:} (1) User request → CloudFront (geographic edge location), (2) CloudFront → ALB (AWS region), (3) ALB → Backend EC2 (least connections), (4) Backend → RDS (authentication, chat history), (5) Backend → S3 (vector store retrieval), (6) Backend → External APIs (Google AI, HuggingFace), (7) Response streams back through same path.

\textbf{Authentication Flow:} (1) User credentials → Backend API, (2) Backend validates against RDS, (3) JWT token generated and returned, (4) Subsequent requests include JWT in Authorization header, (5) Backend validates JWT before processing.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.85\textwidth]{Figure 2.png}
    \caption{Network Topology - VPC Subnet Architecture}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.85\textwidth]{Figure 3.png}
    \caption{Chat Streaming Request Flow Sequence}
\end{figure}

\newpage

% Section 2: Detailed Design
\section{Detailed Design Document}

\subsection{Component Specifications}

\begin{longtable}{|p{2.5cm}|p{6cm}|p{6cm}|}
\hline
\textbf{Tier} & \textbf{Technology Stack} & \textbf{Configuration} \\
\hline
\textbf{Frontend} & Next.js 15.5.7, React 18.3.1, TypeScript 5, Tailwind CSS & t3.medium (2 vCPU, 4 GB), 2--5 instances, 70\% CPU target \\
\hline
\textbf{Backend} & FastAPI 0.104+, Python 3.11, Gunicorn, LangChain, LangGraph & t3.large (2 vCPU, 8 GB), 5 workers, 2--8 instances, 75\% CPU target \\
\hline
\textbf{Database} & PostgreSQL 15, RDS Multi-AZ & db.t3.medium (2 vCPU, 4 GB), 100 GB gp3, 7-day backups \\
\hline
\textbf{Vector Store} & ChromaDB, S3 backend, Google AI embeddings & S3 Standard with EBS cache (100 GB), 1536-dim embeddings \\
\hline
\textbf{Load Balancer} & ALB (Layer 7) & HTTPS (443), health checks, least outstanding requests \\
\hline
\end{longtable}

\subsection{Technology Choices Justification}

\textbf{RDS vs Self-Hosted:} Chose RDS for automated backups, Multi-AZ failover (<60s), reduced operational overhead. Cost premium (30--40\%) acceptable vs 10--15 hours/month maintenance for self-hosted.

\textbf{EC2 vs ECS vs Lambda:} EC2 Auto Scaling for current deployment (predictable performance, better for long-running RAG). ECS Fargate planned for future migration. Lambda unsuitable (15-min timeout, cold starts, limited package size).

\textbf{S3 vs EBS:} S3 for primary storage (99.999999999\% durability, \$0.023/GB vs \$0.10/GB), EBS cache for performance. Cost: \$4.30/month vs \$11/month (61\% savings).

\textbf{ALB vs NLB:} ALB for Layer 7 routing, SSL termination, WAF integration, application health checks. ~100ms latency difference acceptable given AI processing time (2--5 seconds).

\subsection{Frontend Tier}

\textbf{Technology Stack:} Next.js 15.5.7, React 18.3.1, TypeScript 5, Tailwind CSS. UI/UX: Framer Motion, Spline, Radix UI, Glassmorphism design.

\textbf{Deployment:} t3.medium (2 vCPU, 4 GB), 2--5 instances, Docker with Node.js 20. Scaling: CPU >70\% OR Memory >80\% for 2 min (scale out), CPU <30\% AND Memory <50\% for 10 min (scale in). CDN: CloudFront with 1 year TTL (immutable), 1 hour (HTML), TLS 1.2+. Sizing: 1 GB/instance, 50--100 concurrent users/instance.

\subsection{Backend Tier}

\textbf{Technology Stack:} FastAPI 0.104+, Python 3.11, Gunicorn, LangChain, LangGraph, SQLAlchemy.

\textbf{Deployment:} t3.large (2 vCPU, 8 GB), 5 workers per instance, 2--8 instances. Gunicorn: (2×CPU)+1=5 workers, timeout: 120s, max requests: 1000.

\textbf{API Endpoints:} Authentication (\texttt{/auth/*}), Chat Management (\texttt{/chats/*}), Streaming Chat (\texttt{/chat/stream}), RAG Creation (\texttt{/yt\_rag}, \texttt{/pdf\_rag}, \texttt{/web\_rag}, \texttt{/git\_rag}).

\textbf{Scaling:} Scale out: CPU >75\% OR Queue >100 (3 min), scale in: CPU <40\% AND Queue <20 (15 min). Memory: 2.65 GB base + 200 MB/RAG query → 21 concurrent RAG queries/instance.

\subsection{Database Tier}

\textbf{Technology Stack:} PostgreSQL 15, RDS Multi-AZ, db.t3.medium (2 vCPU, 4 GB), 100 GB gp3 storage.

\textbf{Schema:} Users (~1 KB), Chats (~500 bytes), Messages (~5--50 KB), indexes on user\_id, chat\_id, created\_at.

\textbf{Storage:} ~600 MB baseline (100 users, 1000 chats, 20,000 messages), 100 GB allocated for growth. Backup: Automated daily (7-day retention), point-in-time recovery (5-min RPO). Connections: 50--100 (within db.t3.medium limit of 87). Read replicas optional.

\subsection{Vector Store Tier}

\textbf{Technology Stack:} ChromaDB, S3 backend, Google AI embeddings (1536-dim), EBS cache (100 GB gp3).

\textbf{Storage:} S3 Standard (99.999999999\% durability), 100 GB estimated (100 users × 10 collections × 100 MB avg), versioning enabled. Operations: Dynamic chunking, MMR retrieval (k=5), EBS cache with LRU eviction. Cost: \$4.30/month (S3 + EBS cache) vs \$11/month (EBS-only), 61\% savings.

% Section 3: Reliability & Fault Tolerance
\section{Reliability \& Fault-Tolerance Analysis}

\subsection{Failure Modes Identified}

\begin{longtable}{|p{2.8cm}|p{2.5cm}|p{3cm}|p{4.2cm}|}
\hline
\textbf{Failure Mode} & \textbf{Impact} & \textbf{Detection} & \textbf{Recovery} \\
\hline
EC2 instance failure & High & CloudWatch, ALB health checks & ASG replacement (5--10 min RTO) \\
\hline
RDS primary failure & Low & Multi-AZ monitoring & Auto failover (<60s RTO, 0 RPO) \\
\hline
S3 vector store loss & Critical & Data validation checksums & S3 versioning restore \\
\hline
External API failure & High & HTTP monitoring, alarms & Circuit breaker, graceful degradation \\
\hline
DDoS attack & High & AWS Shield, CloudWatch & WAF rate limiting, Shield protection \\
\hline
Backend application crash & High & Process monitoring, error rate alarms & Auto-restart (systemd/ECS), health check removes from ALB \\
\hline
DB connection pool exhaustion & High & CloudWatch metric on connections & Connection pool limits, query timeout, circuit breaker \\
\hline
Vector store corruption & Critical & Data validation checksums & S3 versioning, restore from previous version \\
\hline
Database transaction failure & Medium & Application error logging & Retry with exponential backoff, transaction rollback \\
\hline
Authentication bypass & Critical & Security monitoring, unusual access patterns & Secret rotation, JWT expiration, WAF rules \\
\hline
Network partition & Medium & ALB health checks, CloudWatch & Partial availability, degraded service \\
\hline
\end{longtable}

\subsection{Recovery Behavior and Mechanisms}

\textbf{Automatic Recovery:} EC2 Auto-Recovery (RTO: 5--15 min, RPO: 0), ASG replacement (RTO: 5--10 min, RPO: 0), RDS Multi-AZ failover (RTO: <60s, RPO: 0), Application auto-restart (RTO: 10--30s, RPO: 0).

\textbf{Manual Recovery:} Database point-in-time recovery (RTO: 15--30 min, RPO: 5 min), Vector store restoration (RTO: 5--10 min, RPO: near real-time), Application rollback (RTO: 5--10 min, RPO: 0).

\textbf{Circuit Breaker:} Open after 5 consecutive failures (60s timeout), half-open test request, close on success. Prevents cascading failures from external APIs.

\subsection{Service Level Objectives (SLOs)}

\textbf{Availability:} 99.9\% uptime target (8.76 hours/year downtime, 43.8 min/month), measured via CloudWatch Synthetics, excludes 4xx client errors. Justification: Reasonable for startup/SaaS, allows planned maintenance.

\textbf{Latency:} P50: <1s (normal chat), P95: <2s (normal chat), <5s (RAG queries), P99: <5s (normal chat), <10s (RAG queries). Measured via ALB TargetResponseTime metric. Justification: Normal chat (LLM API: 1--2s), RAG queries (vector search + LLM: 3--5s).

\textbf{Throughput:} 100 concurrent users baseline, scales to 1,000+. Measurement: Active connections, concurrent API requests. Justification: 2--4 instances (5 workers each) = 50--200 concurrent capacity.

\textbf{RTO/RPO:} RTO: <15 min (most failures), <60s (RDS failover). RPO: 0 (zero data loss via Multi-AZ synchronous replication).

\textbf{Redundancy Strategy:}
    \begin{itemize}
    \item Multi-AZ deployment for all critical components
    \item RDS synchronous replication for zero data loss
    \item Auto Scaling Groups with health checks
    \item NAT Gateway redundancy across AZs
    \item S3 cross-region replication (optional)
\end{itemize}

% Section 4: Scalability & Performance
\section{Scalability \& Performance Plan}

\subsection{Scaling Strategy Overview}

\textbf{Horizontal Scaling (Primary):} Auto Scaling Groups, stateless design (JWT tokens, externalized state), ALB load distribution. Advantages: Linear capacity growth, high availability, cost flexibility. Limitations: Network overhead, requires external state storage.

\textbf{Vertical Scaling (Secondary):} Instance type upgrades, Reserved Instances for baseline capacity. Advantages: Simple implementation, better single-instance performance. Limitations: Upper limits, downtime during migration (5--15 min).

\textbf{Hybrid Approach:} Primary horizontal scaling, secondary vertical scaling for database, Reserved Instances for baseline capacity.

\subsection{Auto Scaling Configuration}

\textbf{Frontend ASG:} Min: 2, Desired: 2, Max: 5, t3.medium, Health Check: ELB, Grace Period: 300s.

\textbf{Backend ASG:} Min: 2, Desired: 2--4, Max: 8, t3.large, Health Check: ELB with /health endpoint, Grace Period: 300s.

\textbf{Scaling Triggers:} CPU (>70\% frontend, >75\% backend), Memory (>80\%), Request Count, Queue Depth (Backend: >100 scale out, <20 scale in).

\textbf{Scaling Policies:} Scale-Out: +1 instance, cooldown: 300s. Scale-In: -1 instance when CPU <30--40\% AND Memory <50\% AND Queue <20 for 10--15 periods, cooldown: 600--900s. Step Scaling: +1 to +3 instances based on breach severity. Conservative scale-in: Low-traffic periods only, ensure 2+ instances remain.

\subsection{Performance Optimization}

\textbf{Connection Pooling:} SQLAlchemy (5 connections/worker), prevents exhaustion, automatic retry/timeout.

\textbf{Async Processing:} Async/await for external API calls, concurrent request handling, non-blocking I/O.

\textbf{Caching:} CloudFront (1 year immutable, 1 hour HTML, Gzip/Brotli), Vector store EBS cache (LRU eviction), reduces API calls and improves latency.

\textbf{Database Optimization:} Indexes on user\_id, chat\_id, created\_at, query optimization, connection pool limits.

\textbf{Capacity Planning:} Baseline: 100 users, 1,000 req/day → 2--4 backend instances. Peak: 1,000 users → 8 instances, read replicas. Spike: 10x traffic in 5 min → auto-scaling (3--5 min). Resource targets: CPU 70--75\%, Memory 80--85\%.

% Section 5: Security Design
\section{Security Design}

\textbf{Defense-in-Depth Layers:}
\begin{enumerate}
    \item \textbf{Network Perimeter}: CloudFront with WAF, AWS Shield, DDoS protection
    \item \textbf{Application}: WAF rules, JWT authentication, input validation
    \item \textbf{Infrastructure}: VPC segmentation, security groups (least privilege)
    \item \textbf{Data}: Encryption at rest (AES-256), in transit (TLS 1.2+)
    \item \textbf{Identity}: IAM roles (least privilege), Secrets Manager, audit logging
\end{enumerate}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.85\textwidth]{Figure 4.png}
    \caption{Security Architecture and Trust Boundaries}
\end{figure}

\textbf{Encryption Strategy:}
\begin{longtable}{|p{3cm}|p{6cm}|p{5cm}|}
\hline
\textbf{Data Type} & \textbf{At Rest} & \textbf{In Transit} \\
\hline
RDS & AES-256, KMS-managed keys & TLS 1.2+ (encrypted connections) \\
\hline
S3 & SSE-KMS (AES-256) & HTTPS (TLS 1.2+) \\
\hline
EBS & KMS encryption & N/A (internal VPC) \\
\hline
Secrets & KMS encryption (Secrets Manager) & HTTPS only \\
\hline
\end{longtable}

\textbf{Authentication \& Authorization:}
    \begin{itemize}
    \item JWT-based authentication (256-bit secret, 30-day expiration)
    \item Password hashing: bcrypt (work factor 12)
    \item IAM roles for EC2 instances (no long-lived credentials)
    \item Security groups: Allow only required ports from specific sources
    \item Network ACLs: Additional layer of network protection
\end{itemize}

\textbf{Authentication \& Authorization:} JWT authentication (256-bit secret, 30-day expiration), password hashing (bcrypt, work factor 12), IAM roles for EC2 (no long-lived credentials, least privilege policies).

\textbf{Network Segmentation:} VPC: 10.0.0.0/16, Public subnets (ALB, NAT Gateway), Private app subnets (EC2 backend), Private data subnets (RDS), Multi-AZ deployment. Security Groups: ALB (HTTPS 443 from CloudFront), Backend EC2 (HTTP 8000 from ALB only), RDS (PostgreSQL 5432 from backend only). Network ACLs: Additional layer, stateless rules, default deny-all.

\textbf{Security Monitoring:} CloudWatch security metrics (failed auth, unusual access, error rates), CloudTrail (API audit logging, log encryption with KMS), GuardDuty (optional threat detection). Incident Response: Procedures for data breach, unauthorized access, DDoS attacks. Compliance: GDPR (encryption, access controls, data retention), SOC 2 (security controls, audit logging), data residency (EU region).

% Section 6: Operational Plan
\section{Operational Plan}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.85\textwidth]{Figure 5.png}
    \caption{CI/CD Pipeline Flow Diagram}
\end{figure}

\textbf{CI/CD Pipeline Stages:} (1) Source Control: GitHub, PR reviews (2 approvals), branch protection. (2) Build: Docker image build, dependency installation, linting. (3) Test: Unit tests (>70\% coverage), integration tests, security scans. (4) Deploy Staging: Automatic for develop branch, smoke tests. (5) Deploy Production: Manual approval, blue-green/canary deployment, monitor 1 hour. (6) Post-Deployment: Smoke tests, monitoring, rollback if error rate >5\% or response time >2x baseline.

\textbf{Monitoring \& Alerting:}
\begin{longtable}{|p{3cm}|p{5.5cm}|p{5cm}|}
\hline
\textbf{Metric} & \textbf{Threshold} & \textbf{Action} \\
\hline
CPU Utilization & >80\% for 5 min & Scale out, investigate \\
\hline
Memory Usage & >85\% for 5 min & Scale out, check for leaks \\
\hline
Error Rate & >5\% for 5 min & Alert, investigate, rollback \\
\hline
Response Time & >2x baseline for 10 min & Alert, investigate \\
\hline
Database Connections & >80\% of max & Alert, check connection pool \\
\hline
\end{longtable}

\textbf{Runbooks (Top Incidents):}

\textbf{High Error Rate:} Check CloudWatch logs, verify external APIs, check database connectivity, review recent deployments. Resolution: Rollback if code issue, activate circuit breaker if external API, scale out if overloaded. Escalate after 15 min if unresolved.

\textbf{Database Failure:} Verify Multi-AZ failover status, check RDS metrics (CPU, connections, replication lag). Resolution: Failover should occur automatically (<60s), restore from backup if data corruption (RTO: 15--30 min, RPO: 5 min). Escalate immediately if failover unsuccessful.

\textbf{Instance Unhealthy:} Check /health endpoint, review application logs, check CPU/memory utilization. Resolution: Restart service if application error, ASG automatically replaces failed instance (5--10 min). Escalate if multiple instances unhealthy.

\textbf{High Response Time:} Check CPU/memory utilization, review database query performance, check external API response times, verify auto-scaling. Resolution: Scale out if overloaded, optimize queries, check network connectivity.

\textbf{DDoS Attack:} Check CloudWatch metrics for traffic spike, review AWS Shield alerts, check WAF blocked requests. Resolution: Shield Standard mitigates automatically, WAF rate limiting blocks suspicious traffic. Escalate to security team immediately.

\textbf{Backup \& Disaster Recovery:} RDS: Automated daily backups (7-day retention), point-in-time recovery (5-min RPO), manual snapshots before major changes. S3: Versioning enabled, cross-region replication optional, lifecycle policies (Glacier after 90 days). DR Scenarios: Single AZ failure → Multi-AZ failover automatic, Region failure → Manual restoration (future: cross-region replication). Backup Verification: Monthly restore drills.

\textbf{Change Management:} All production changes require PR review (2 approvals), major changes require team lead approval. Deployment windows: Business hours (09:00--17:00 UTC), database maintenance (02:00--04:00 UTC). Rollback: Application (previous Docker image/AMI, 5--10 min), Database (restore from backup if migrations applied). Database Migrations: Alembic, test on staging first, create backup before production, test rollback procedure.

% Section 7: Cost Estimate
\section{Cost Estimate \& Optimization}

\textbf{Baseline Monthly Cost (eu-north-1, 100 users, 1,000 req/day):}
\begin{longtable}{|p{4cm}|p{6cm}|p{4cm}|}
\hline
\textbf{Service} & \textbf{Configuration} & \textbf{Monthly Cost} \\
\hline
EC2 Frontend (2×t3.medium) & 2 instances, 24/7, 60 GB EBS & \$67.64 \\
\hline
EC2 Backend (2×t3.large) & 2 instances, 24/7, 200 GB EBS & \$144.47 \\
\hline
RDS (db.t3.medium Multi-AZ) & 2 instances, 100 GB gp3 & \$116.62 \\
\hline
ALB & 1 load balancer & \$22.00 \\
\hline
CloudFront & CDN distribution, 50 GB transfer & \$10.00 \\
\hline
NAT Gateway (2×AZ) & 2 gateways, 100 GB transfer & \$72.00 \\
\hline
S3 Storage & 210 GB (vectors+static+logs) & \$5.00 \\
\hline
Secrets Manager & 5 secrets & \$2.50 \\
\hline
CloudWatch & Metrics, logs, alarms & \$15.00 \\
\hline
Data Transfer & Inter-AZ, internet egress & \$20.00 \\
\hline
\textbf{Total Baseline} & & \textbf{\$475.23} \\
\hline
\end{longtable}

\textbf{Optimization Options:}
\begin{longtable}{|p{3cm}|p{6cm}|p{4.5cm}|}
\hline
\textbf{Strategy} & \textbf{Implementation} & \textbf{Savings} \\
\hline
Reserved Instances & 1-year term, 30\% upfront, 2×t3.large + 2×t3.medium & 30\% (\$63/month) \\
\hline
S3 Intelligent-Tiering & Automatic cost optimization & 10--20\% (\$1/month) \\
\hline
Right-Sizing & Monitor and adjust instance types & 10--15\% (\$50/month) \\
\hline
NAT Gateway Optimization & Single NAT (dev), VPC endpoints & 50\% (\$36/month) \\
\hline
\textbf{Optimized Total} & & \textbf{\$325--350/month} \\
\hline
\end{longtable}

\textbf{Cost per User:} Baseline: \$4.75/user/month; Optimized: \$3.25--3.50/user/month

\textbf{Cost Optimization Strategies:} Reserved Instances (1-year term): 30\% discount, savings: \$63/month. S3 Intelligent-Tiering: Automatic optimization, savings: 10--20\% (\$1/month). Right-Sizing: Monitor and adjust instance types, savings: 10--15\% (\$50/month). NAT Gateway Optimization: Single NAT, VPC endpoints, savings: 50\% (\$36/month). Cost Monitoring: AWS Cost Explorer, Budget alerts (80\%, 100\%), cost allocation tags, monthly reviews.

\newpage

% Section 8: Testing Strategy
\section{Testing Strategy}

\textbf{Testing Levels:}
\begin{longtable}{|p{3cm}|p{5cm}|p{6cm}|}
\hline
\textbf{Level} & \textbf{Scope} & \textbf{Pass Criteria} \\
\hline
Unit Tests (70\%) & Individual functions, components & >70\% code coverage, all tests pass \\
\hline
Integration Tests (20\%) & API endpoints, DB operations & All endpoints return correct status codes \\
\hline
E2E Tests (10\%) & Complete user workflows & All critical paths complete successfully \\
\hline
Load Tests & 100--1,000 concurrent users & 95th percentile latency <2s, error rate <1\% \\
\hline
Chaos Engineering & Instance failures, API failures & System recovers automatically, RTO <15 min \\
\hline
\end{longtable}

\textbf{Load Testing Scenarios:} Baseline: 100 users, 50 req/min → Verify <200ms latency, <1\% error rate. Peak: 1,000 users, 500 req/min → Verify auto-scaling (3--5 min), <2s latency. Spike: 10x traffic in 5 min → Verify rapid scale-out, no failures. Stress: Exceed capacity → Verify graceful degradation, <5\% error rate. Endurance: 24-hour sustained load → Verify no memory leaks, stable performance.

\textbf{Chaos Engineering:} EC2 termination → ASG replacement (5--10 min), no data loss. RDS primary failure → Multi-AZ failover (<60s), zero data loss. External API failure → Circuit breaker activation, graceful degradation. Network partition → Partial availability, RDS failover if needed.

\textbf{Security Testing:} Penetration testing (OWASP Top 10, SQL injection, XSS, auth bypass), Vulnerability scanning (dependencies, Docker images, infrastructure), Security audits (quarterly reviews, IAM audits, compliance audits).

% Section 9: Conclusion
\section{Conclusion and Future Work}

\subsection{Executive Summary of Architecture}

The SONYC architecture represents a production-ready design for deploying a RAG application on AWS, addressing security, scalability, reliability, and operational excellence. Key decisions: Multi-tier architecture, AWS managed services (RDS, ALB, CloudFront), Multi-AZ deployment (99.9\% availability), defense-in-depth security, cost-optimized infrastructure (t3 instances, Reserved Instances).

\subsection{Key Achievements}

\textbf{Reliability:} Multi-AZ database (automatic failover <60s, zero data loss), automatic recovery (ASG replacement, health checks), fault tolerance (no single points of failure, circuit breakers), comprehensive monitoring. Target: 99.9\% uptime achieved.

\textbf{Security:} End-to-end encryption (TLS/SSL, AES-256), network segmentation (four trust boundaries), DDoS protection (WAF, Shield), JWT authentication, GDPR/SOC 2 compliance ready.

\textbf{Scalability:} Baseline: 100 concurrent users, scales to 1,000+, horizontal scaling (Auto Scaling Groups), vertical scaling capability, efficient load distribution (ALB, CloudFront).

\textbf{Performance:} <200ms latency for chat initiation, >90\% hallucination reduction via RAG, validated 99.9\% uptime in development environments.

\textbf{Cost:} Baseline: \$475/month, Optimized: \$325--350/month (with Reserved Instances), Cost per user: \$3.25--3.50/user/month (optimized).

\subsection{Limitations and Constraints}

Single region deployment (eu-north-1), Reserved Instances pending implementation, Advanced monitoring (X-Ray) and caching (Redis) planned for future, Budget constraints limit maximum capacity (8 instances), External API dependencies.

\subsection{Future Enhancements}

\textbf{Short-Term (3--6 months):} Multi-region deployment, AWS X-Ray, Redis caching, GuardDuty, Reserved Instances.

\textbf{Medium-Term (6--12 months):} ECS Fargate migration, distributed vector database, advanced RAG techniques, read replicas.

\textbf{Long-Term (12+ months):} Microservices architecture, ML pipeline, voice integration, mobile app, multi-cloud.

\subsection{Lessons Learned}

Architecture design requires balancing cost, performance, and security through trade-off analysis. Production architecture differs significantly from development setup. Managed services reduce operational overhead. Scalability and security must be designed from day one. Comprehensive monitoring, documentation, and testing strategies are essential for production systems.

\newpage

% Section 10: Risk Register
\section{Risk Register \& Mitigation Plan}

\subsection{Top 8 Risks with Mitigation Plans}

\begin{longtable}{|p{1.2cm}|p{2cm}|p{1.8cm}|p{1.8cm}|p{5.2cm}|}
\hline
\textbf{ID} & \textbf{Risk} & \textbf{Impact} & \textbf{Prob.} & \textbf{Key Mitigations} \\
\hline
R1 & Data breach & Critical & Medium & Encryption (at rest/in transit), IAM roles (least privilege), WAF rules, network segmentation, CloudTrail audit logging, regular security audits \\
\hline
R2 & External API failure & High & Medium & Circuit breaker pattern (5 failures, 60s timeout), fallback responses, monitoring/alarms, retry logic (exponential backoff), graceful degradation \\
\hline
R3 & Cost overruns & Medium & Medium & Reserved Instances (30\% savings), AWS Budgets alerts, Cost Explorer monitoring, right-sizing, cost allocation tags, monthly reviews \\
\hline
R4 & Scalability bottlenecks & High & Low & Auto-scaling groups (2--8 instances), load testing (baseline/peak/spike), capacity planning, monitoring metrics, performance optimization \\
\hline
R5 & Single region deployment & Medium & Low & Multi-AZ deployment (current), cross-region replication (optional S3), multi-region deployment (future enhancement) \\
\hline
R6 & Database failure & Critical & Low & RDS Multi-AZ (automatic failover <60s), automated backups (7-day retention), point-in-time recovery (5-min RPO), read replicas for scaling \\
\hline
R7 & Compliance violations & High & Low & GDPR compliance (encryption, access controls, data retention), SOC 2 controls (security, monitoring, audit logging), regular compliance audits, data residency (EU region) \\
\hline
R8 & Key personnel dependency & Medium & Low & Comprehensive documentation, knowledge sharing sessions, code reviews, runbooks, cross-training team members \\
\hline
\end{longtable}

\textbf{R1: Data Breach:} Encryption (at rest/in transit), IAM roles (least privilege), WAF rules, network segmentation, CloudTrail audit logging, security audits.

\textbf{R2: External API Failure:} Circuit breaker pattern (5 failures, 60s timeout), fallback responses, monitoring/alarms, retry logic, graceful degradation.

\textbf{R3: Cost Overruns:} Reserved Instances (30\% savings), AWS Budgets alerts, Cost Explorer, right-sizing, monthly reviews.

\textbf{R4: Scalability Bottlenecks:} Auto-scaling (2--8 instances), load testing, capacity planning, performance monitoring, optimization (connection pooling, caching).

\textbf{R5: Single Region Deployment:} Multi-AZ deployment (current), cross-region replication (optional), multi-region (future), disaster recovery plan.

\textbf{R6: Database Failure:} RDS Multi-AZ (automatic failover <60s, 0 RPO), automated backups (7-day retention), point-in-time recovery (5-min RPO), read replicas, manual snapshots.

\textbf{R7: Compliance Violations:} GDPR compliance (encryption, access controls, data retention, right to erasure), SOC 2 controls (security, monitoring, audit logging), quarterly audits, data residency (EU region).

\textbf{R8: Key Personnel Dependency:} Comprehensive documentation, knowledge sharing sessions, detailed runbooks, cross-training, version control.

\subsection{Risk Monitoring and Review}

Quarterly risk review meetings, risks updated based on incidents and testing results, critical risks (R1, R6) escalate immediately, integration with incident response procedures, risk mitigations tested through chaos engineering and security audits.

% Team Reflection
\section*{Team Reflection}

\textbf{Team Overview:} 5 members (Abdullah, Muhammad Azfar, Muhammad Affan, Muhammad Hamza Haider, Muhammad Muhad), Cloud Computing (SE-315), BESE29-A.

\textbf{Individual Contributions:}
\begin{itemize}
    \item \textbf{Abdullah}: Sections 1 (Architecture), 4 (Scalability), 5 (Security), report editing, team coordination
    \item \textbf{Muhammad Azfar}: Sections 2 (Design), 3 (Reliability)
    \item \textbf{Muhammad Affan}: Sections 8 (Testing), 9 (Conclusion), architecture diagrams
    \item \textbf{Muhammad Hamza Haider}: Sections 7 (Cost), 8 (Testing contributions), 9 (Conclusion contributions)
    \item \textbf{Muhammad Muhad}: Section 6 (Operational Plan), 7 (Cost contributions)
\end{itemize}

\textbf{Key Learnings:} This project provided comprehensive exposure to cloud architecture design, covering security, scalability, reliability, and operations. The experience emphasized balancing competing requirements (cost, performance, security), the importance of documentation and operational procedures, and systematic risk management. The project directly applied course concepts including multi-tier architecture, AWS services, security best practices, and operational excellence.

\end{document}
